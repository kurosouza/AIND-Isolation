{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "\n",
    "# isolation.Board class\n",
    "\n",
    "## Constructor\n",
    "\n",
    "    Board.__init__(self, player_1, player_2, width=7, height=7)\n",
    "\n",
    "## Attributes\n",
    "\n",
    "### BLANK : 0 (constant)\n",
    "\n",
    "### NOT_MOVED : None (constant)\n",
    "\n",
    "### width : 7 (constant)\n",
    "\n",
    "Board width\n",
    "\n",
    "### height : 7 (constant)\n",
    "\n",
    "Board height\n",
    "\n",
    "### active_player : hashable\n",
    "\n",
    "Reference to a hashable object registered as a player with the initiative to move on the current board\n",
    "\n",
    "### inactive_player : hashable\n",
    "\n",
    "Reference to a hashable object registered as a player awaiting initiative to move on the current board\n",
    "\n",
    "### move_count : int\n",
    "\n",
    "Counter indicating the number of moves that have been applied to the game\n",
    "\n",
    "## Public Methods\n",
    "\n",
    "### apply_move(self, move)\n",
    "    \n",
    "Modify the game object by moving the active player on the game board and disabling the vacated square (if any). The forecast_move method performs the same function, but returns a copy of the board, rather than modifying the state in-place.\n",
    "\n",
    "### copy(self)\n",
    "\n",
    "Return a new Board object that is a copy of the current game state\n",
    "\n",
    "### forecast_move(self, move)\n",
    "\n",
    "Equivalent to apply_move, but returns a copy of the board rather than modifying the state in-place.\n",
    "\n",
    "### get_blank_spaces(self)\n",
    "\n",
    "Returns a list of tuples identifying the blank squares on the current board\n",
    "\n",
    "### get_legal_moves(self, player=None)\n",
    "\n",
    "Returns a list of tuples identifying the legal moves for the specified player\n",
    "\n",
    "### get_opponent(self, player)\n",
    "\n",
    "Returns the opponent of the specified player\n",
    "\n",
    "### get_player_location(self, player)\n",
    "\n",
    "Returns a tuple (x, y) identifying the location of the specified player on the game board, or None of the player is a registered agent in the game but has not yet been placed on the board. Raises a RuntimeError if the specified player is not registered on the board.\n",
    "\n",
    "### hash(self)\n",
    "\n",
    "Return a hash of the current state (public alias of __hash__ method). The hashed state includes occupied cells, current player locations, and which player has initiative on the board. An equivalent hash function can be added to the isolation.Board class from the isolation project:\n",
    "\n",
    "### is_loser(self, player)\n",
    "\n",
    "Returns True if the specified player has lost the game in the current state, and False otherwise\n",
    "\n",
    "### is_winner(self, player)\n",
    "\n",
    "Returns True if the specified player has won the game in the current state, and False otherwise\n",
    "\n",
    "### move_is_legal(self, move)\n",
    "\n",
    "Returns True if the active player can legally make the specified move and False otherwise\n",
    "\n",
    "### to_string(self, symbols=['1', '2'])\n",
    "\n",
    "Return a string representation of the current board position\n",
    "\n",
    "### utility(self, player)\n",
    "\n",
    "Returns a floating point value: +inf if the specified player has won the game, -inf if the specified player has lost the game, and 0 otherwise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Build a Game-playing Agent\n",
    "\n",
    "![Example game of isolation](viz.gif)\n",
    "\n",
    "## Synopsis\n",
    "\n",
    "In this project, students will develop an adversarial search agent to play the game \"Isolation\".  Isolation is a deterministic, two-player game of perfect information in which the players alternate turns moving a single piece from one cell to another on a board.  Whenever either player occupies a cell, that cell becomes blocked for the remainder of the game.  The first player with no remaining legal moves loses, and the opponent is declared the winner.  These rules are implemented in the `isolation.Board` class provided in the repository. \n",
    "\n",
    "This project uses a version of Isolation where each agent is restricted to L-shaped movements (like a knight in chess) on a rectangular grid (like a chess or checkerboard).  The agents can move to any open cell on the board that is 2-rows and 1-column or 2-columns and 1-row away from their current position on the board. Movements are blocked at the edges of the board (the board does not wrap around), however, the player can \"jump\" blocked or occupied spaces (just like a knight in chess).\n",
    "\n",
    "Additionally, agents will have a fixed time limit each turn to search for the best move and respond.  If the time limit expires during a player's turn, that player forfeits the match, and the opponent wins.\n",
    "\n",
    "Students only need to modify code in the `game_agent.py` file to complete the project.  Additional files include example Player and evaluation functions, the game board class, and a template to develop local unit tests.  \n",
    "\n",
    "\n",
    "## Instructions\n",
    "\n",
    "In order to complete the Isolation project, students must submit code that passes all test cases for the required functions in `game_agent.py` and complete a report as specified in the rubric.  Students can submit using the [Udacity Project Assistant]() command line utility.  Students will receive feedback on test case success/failure after each submission.\n",
    "\n",
    "Students must implement the following functions:\n",
    "\n",
    "- `MinimaxPlayer.minimax()`: implement minimax search\n",
    "- `AlphaBetaPlayer.alphabeta()`: implement minimax search with alpha-beta pruning\n",
    "- `AlphaBetaPlayer.get_move()`: implement iterative deepening search\n",
    "- `custom_score()`: implement your own best position evaluation heuristic\n",
    "- `custom_score_2()`: implement your own alternate position evaluation heuristic\n",
    "- `custom_score_3()`: implement your own alternate position evaluation heuristic\n",
    "\n",
    "You may write or modify code within each file (but you must maintain compatibility with the function signatures provided).  You may add other classes, functions, etc., as needed, but it is not required.\n",
    "\n",
    "The Project Assistant sandbox for this project places some restrictions on the modules available and blocks calls to some of the standard library functions.  In general, standard library functions that introspect code running in the sandbox are blocked, and the PA only allows the following modules `random`, `numpy`, `scipy`, `sklearn`, `itertools`, `math`, `heapq`, `collections`, `array`, `copy`, and `operator`. (Modules within these packages are also allowed, e.g., `numpy.random`.)\n",
    "\n",
    "\n",
    "### Quickstart Guide\n",
    "\n",
    "The following example creates a game and illustrates the basic API.  You can run this example by activating your aind anaconda environment and executing the command `python sample_players.py`\n",
    "\n",
    "    from isolation import Board\n",
    "    from sample_players import RandomPlayer\n",
    "    from sample_players import GreedyPlayer\n",
    "\n",
    "    # create an isolation board (by default 7x7)\n",
    "    player1 = RandomPlayer()\n",
    "    player2 = GreedyPlayer()\n",
    "    game = Board(player1, player2)\n",
    "\n",
    "    # place player 1 on the board at row 2, column 3, then place player 2 on\n",
    "    # the board at row 0, column 5; display the resulting board state.  Note\n",
    "    # that the .apply_move() method changes the calling object in-place.\n",
    "    game.apply_move((2, 3))\n",
    "    game.apply_move((0, 5))\n",
    "    print(game.to_string())\n",
    "\n",
    "    # players take turns moving on the board, so player1 should be next to move\n",
    "    assert(player1 == game.active_player)\n",
    "\n",
    "    # get a list of the legal moves available to the active player\n",
    "    print(game.get_legal_moves())\n",
    "\n",
    "    # get a successor of the current state by making a copy of the board and\n",
    "    # applying a move. Notice that this does NOT change the calling object\n",
    "    # (unlike .apply_move()).\n",
    "    new_game = game.forecast_move((1, 1))\n",
    "    assert(new_game.to_string() != game.to_string())\n",
    "    print(\"\\nOld state:\\n{}\".format(game.to_string()))\n",
    "    print(\"\\nNew state:\\n{}\".format(new_game.to_string()))\n",
    "\n",
    "    # play the remainder of the game automatically -- outcome can be \"illegal\n",
    "    # move\", \"timeout\", or \"forfeit\"\n",
    "    winner, history, outcome = game.play()\n",
    "    print(\"\\nWinner: {}\\nOutcome: {}\".format(winner, outcome))\n",
    "    print(game.to_string())\n",
    "    print(\"Move history:\\n{!s}\".format(history))\n",
    "\n",
    "\n",
    "### Coding\n",
    "\n",
    "The steps below outline a suggested process for completing the project -- however, this is just a suggestion to help you get started.  A stub for writing unit tests is provided in the `agent_test.py` file (no local test cases are provided). (See the [unittest](https://docs.python.org/3/library/unittest.html#basic-example) module for information on getting started.)\n",
    "\n",
    "The primary mechanism for testing your code will be the Udacity Project Assistant command line utility.  You can install the Udacity-PA tool by activating your aind anaconda environment, then running `pip install udacity-pa`.  You can submit your code for scoring by running `udacity submit isolation`.  The project assistant server has a collection of unit tests that it will execute on your code, and it will provide feedback on any successes or failures.  You must pass all test cases in the project assistant before you can complete the project by submitting your report for review.\n",
    "\n",
    "0. Verify that the Udacity-PA tool is installed properly by submitting the project. Run `udacity submit isolation`. (You should see a list of test cases that failed -- that's expected because you haven't implemented any code yet.)\n",
    "\n",
    "0. Modify the `MinimaxPlayer.minimax()` method to return any legal move for the active player.  Resubmit your code to the project assistant and the minimax interface test should pass.\n",
    "\n",
    "0. Further modify the `MinimaxPlayer.minimax()` method to implement the full recursive search procedure described in lecture (ref. [AIMA Minimax Decision](https://github.com/aimacode/aima-pseudocode/blob/master/md/Minimax-Decision.md)).  Resubmit your code to the project assistant and both the minimax interface and functional test cases will pass.\n",
    "\n",
    "0. Start on the alpha beta test cases. Modify the `AlphaBetaPlayer.alphabeta()` method to return any legal move for the active player.  Resubmit your code to the project assistant and the alphabeta interface test should pass.\n",
    "\n",
    "0. Further modify the `AlphaBetaPlayer.alphabeta()` method to implement the full recursive search procedure described in lecture (ref. [AIMA Alpha-Beta Search](https://github.com/aimacode/aima-pseudocode/blob/master/md/Alpha-Beta-Search.md)).  Resubmit your code to the project assistant and both the alphabeta interface and functional test cases will pass.\n",
    "\n",
    "0. You can pass the interface test for the `AlphaBetaPlayer.get_move()` function by copying the code from `MinimaxPlayer.get_move()`.  Resubmit your code to the project assistant to see that the `get_move()` interface test case passes.\n",
    "\n",
    "0. Pass the test_get_move test by modifying `AlphaBetaPlayer.get_move()` to implement Iterative Deepening.  See Also [AIMA Iterative Deepening Search](https://github.com/aimacode/aima-pseudocode/blob/master/md/Iterative-Deepening-Search.md)\n",
    "\n",
    "0. Finally, pass the heuristic tests by implementing any heuristic in `custom_score()`, `custom_score_2()`, and `custom_score_3()`.  (These test cases only validate the return value type -- it does not check for \"correctness\" of your heuristic.)  You can see example heuristics in the `sample_players.py` file.\n",
    "\n",
    "\n",
    "### Tournament\n",
    "\n",
    "The `tournament.py` script is used to evaluate the effectiveness of your custom heuristics.  The script measures relative performance of your agent (named \"Student\" in the tournament) in a round-robin tournament against several other pre-defined agents.  The Student agent uses time-limited Iterative Deepening along with your custom heuristics.\n",
    "\n",
    "The performance of time-limited iterative deepening search is hardware dependent (faster hardware is expected to search deeper than slower hardware in the same amount of time).  The script controls for these effects by also measuring the baseline performance of an agent called \"ID_Improved\" that uses Iterative Deepening and the improved_score heuristic defined in `sample_players.py`.  Your goal is to develop a heuristic such that Student outperforms ID_Improved. (NOTE: This can be _very_ challenging!)\n",
    "\n",
    "The tournament opponents are listed below. (See also: sample heuristics and players defined in sample_players.py)\n",
    "\n",
    "- Random: An agent that randomly chooses a move each turn.\n",
    "- MM_Open: MinimaxPlayer agent using the open_move_score heuristic with search depth 3\n",
    "- MM_Center: MinimaxPlayer agent using the center_score heuristic with search depth 3\n",
    "- MM_Improved: MinimaxPlayer agent using the improved_score heuristic with search depth 3\n",
    "- AB_Open: AlphaBetaPlayer using iterative deepening alpha-beta search and the open_move_score heuristic\n",
    "- AB_Center: AlphaBetaPlayer using iterative deepening alpha-beta search and the center_score heuristic\n",
    "- AB_Improved: AlphaBetaPlayer using iterative deepening alpha-beta search and the improved_score heuristic\n",
    "\n",
    "## Submission\n",
    "\n",
    "Before submitting your solution to a reviewer, you are required to submit your project to Udacity's Project Assistant, which will provide some initial feedback.\n",
    "\n",
    "Please see the instructions in the [AIND-Sudoku](https://github.com/udacity/AIND-Sudoku#submission) project repository for installation and setup instructions. \n",
    "\n",
    "To submit your code to the project assistant, run `udacity submit isolation` from within the top-level directory of this project. You will be prompted for a username and password. If you login using google or facebook, follow the [instructions for using a jwt](https://project-assistant.udacity.com/faq).\n",
    "\n",
    "This process will create a zipfile in your top-level directory named `isolation-<id>.zip`. This is the file that you should submit to the Udacity reviews system.\n",
    "\n",
    "\n",
    "## Game Visualization\n",
    "\n",
    "The `isoviz` folder contains a modified version of chessboard.js that can animate games played on a 7x7 board.  In order to use the board, you must run a local webserver by running `python -m http.server 8000` from your project directory (you can replace 8000 with another port number if that one is unavailable), then open your browser to `http://localhost:8000` and navigate to the `/isoviz/display.html` page.  Enter the move history of an isolation match (i.e., the array returned by the Board.play() method) into the text area and run the match.  Refresh the page to run a different game.  (Feel free to submit pull requests with improvements to isoviz.)\n",
    "\n",
    "\n",
    "## PvP Competition\n",
    "\n",
    "Once your project has been reviewed and accepted by meeting all requirements of the rubric, you are invited to complete the `competition_agent.py` file using any combination of techniques and improvements from lectures or online, and then submit it to compete in a tournament against other students from your cohort and past cohort champions.  Additional details (official rules, submission deadline, etc.) will be provided separately.\n",
    "\n",
    "The competition agent can be submitted using the Udacity project assistant:\n",
    "\n",
    "    udacity submit isolation-pvp\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# MINIMAX-DECISION\n",
    "\n",
    "## AIMA3e\n",
    "__function__ MINIMAX-DECISION(_state_) __returns__ _an action_  \n",
    "&emsp;__return__ arg max<sub> _a_ &Element; ACTIONS(_s_)</sub> MIN\\-VALUE(RESULT(_state_, _a_))  \n",
    "\n",
    "---\n",
    "__function__ MAX\\-VALUE(_state_) __returns__ _a utility value_  \n",
    "&emsp;__if__ TERMINAL\\-TEST(_state_) __then return__ UTILITY(_state_)  \n",
    "&emsp;_v_ &larr; &minus;&infin;  \n",
    "&emsp;__for each__ _a_ __in__ ACTIONS(_state_) __do__  \n",
    "&emsp;&emsp;&emsp;_v_ &larr; MAX(_v_, MIN\\-VALUE(RESULT(_state_, _a_)))  \n",
    "&emsp;__return__ _v_  \n",
    "\n",
    "---\n",
    "__function__ MIN\\-VALUE(_state_) __returns__ _a utility value_  \n",
    "&emsp;__if__ TERMINAL\\-TEST(_state_) __then return__ UTILITY(_state_)  \n",
    "&emsp;_v_ &larr; &infin;  \n",
    "&emsp;__for each__ _a_ __in__ ACTIONS(_state_) __do__  \n",
    "&emsp;&emsp;&emsp;_v_ &larr; MIN(_v_, MAX\\-VALUE(RESULT(_state_, _a_)))  \n",
    "&emsp;__return__ _v_  \n",
    "\n",
    "---\n",
    "__Figure__ ?? An algorithm for calculating minimax decisions. It returns the action corresponding to the best possible move, that is, the move that leads to the outcome with the best utility, under the assumption that the opponent plays to minimize utility. The functions MAX\\-VALUE and MIN\\-VALUE go through the whole game tree, all the way to the leaves, to determine the backed\\-up value of a state. The notation argmax <sub>_a_ &Element; _S_</sub> _f_(_a_) computes the element _a_ of set _S_ that has maximum value of _f_(_a_).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# ALPHA-BETA-SEARCH\n",
    "\n",
    "## AIMA3e\n",
    "__function__ ALPHA-BETA-SEARCH(_state_) __returns__ an action  \n",
    "&emsp;_v_ &larr; MAX\\-VALUE(_state_, &minus;&infin;, &plus;&infin;)  \n",
    "&emsp;__return__ the _action_ in ACTIONS(_state_) with value _v_  \n",
    "\n",
    "---\n",
    "__function__ MAX\\-VALUE(_state_, _&alpha;_, _&beta;_) __returns__ _a utility value_  \n",
    "&emsp;__if__ TERMINAL\\-TEST(_state_) __the return__ UTILITY(_state_)  \n",
    "&emsp;_v_ &larr; &minus;&infin;  \n",
    "&emsp;__for each__ _a_ __in__ ACTIONS(_state_) __do__  \n",
    "&emsp;&emsp;&emsp;_v_ &larr; MAX(_v_, MIN\\-VALUE(RESULT(_state_, _a_), _&alpha;_, _&beta;_))  \n",
    "&emsp;&emsp;&emsp;__if__ _v_ &ge; _&beta;_ __then return__ _v_  \n",
    "&emsp;&emsp;&emsp;_&alpha;_ &larr; MAX(_&alpha;_, _v_)  \n",
    "&emsp;__return__ _v_  \n",
    "\n",
    "---\n",
    "__function__ MIN\\-VALUE(_state_, _&alpha;_, _&beta;_) __returns__ _a utility value_  \n",
    "&emsp;__if__ TERMINAL\\-TEST(_state_) __the return__ UTILITY(_state_)  \n",
    "&emsp;_v_ &larr; &plus;&infin;  \n",
    "&emsp;__for each__ _a_ __in__ ACTIONS(_state_) __do__  \n",
    "&emsp;&emsp;&emsp;_v_ &larr; MIN(_v_, MAX\\-VALUE(RESULT(_state_, _a_), _&alpha;_, _&beta;_))  \n",
    "&emsp;&emsp;&emsp;__if__ _v_ &le; _&alpha;_ __then return__ _v_  \n",
    "&emsp;&emsp;&emsp;_&beta;_ &larr; MIN(_&beta;_, _v_)  \n",
    "&emsp;__return__ _v_  \n",
    "\n",
    "\n",
    "---\n",
    "__Figure__ ?? The alpha\\-beta search algorithm. Notice that these routines are the same as the MINIMAX functions in Figure ??, except for the two lines in each of MIN\\-VALUE and MAX\\-VALUE that maintain _&alpha;_ and _&beta;_ (and the bookkeeping to pass these parameters along).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# ITERATIVE-DEEPENING-SEARCH\n",
    "\n",
    "## AIMA3e\n",
    "__function__ ITERATIVE-DEEPENING-SEARCH(_problem_) __returns__ a solution, or failure  \n",
    "&emsp;__for__ _depth_ = 0 to &infin; __do__  \n",
    "&emsp;&emsp;&emsp;_result_ &larr; DEPTH\\-LIMITED\\-SEARCH(_problem_,_depth_)  \n",
    "&emsp;&emsp;&emsp;__if__ _result_ &ne; cutoff __then return__ _result_\n",
    "\n",
    "---\n",
    "__Figure__ ?? The iterative deepening search algorithm, which repeatedly applies depth\\-limited search with increasing limits. It terminates when a solution is found or if the depth\\-limited search returns _failure_, meaning that no solution exists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
